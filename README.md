# Data Science Playground — Environment Setup

## 📌 Project Overview
This repository documents the setup of a clean, modular Python data science environment on macOS.  
It uses **pyenv** for Python version management, **poetry** for dependency and virtual environment management, and integrates **JupyterLab**, **VS Code**, and **GitHub Copilot** for AI-assisted workflows.

The goal is to establish a reliable, reproducible base for data scraping, cleaning, analysis, and visualization projects — with all progress tracked in a **Custom GPT “Data Science Coach”**.

---

## 🖥 Environment Setup Summary
**Operating System:** macOS  
**Python Version Manager:** pyenv  
**Dependency Manager:** poetry  
**Editors:** VS Code + JupyterLab  
**Version Control:** Git + GitHub  
**AI Tools:** GitHub Copilot + ChatGPT (GPT-5) with Advanced Data Analysis

---

## 📂 Folder Structure
data_science_playground/
│
├── notebooks/ # Jupyter notebooks
├── scripts/ # Standalone Python scripts
├── data/ # Raw and cleaned datasets
├── README.md # Project documentation
└── pyproject.toml # Poetry dependency file

---

## 📦 Core Libraries Installed
**Data Handling:** pandas, polars, pyarrow, duckdb, sqlite-utils  
**Visualization:** matplotlib, seaborn, plotly  
**Scraping:** requests, beautifulsoup4, playwright  
**Jupyter:** jupyterlab, ipykernel  

---

## 🚀 Setup Instructions
1. Install [Homebrew](https://brew.sh/)  
2. Install pyenv & latest stable Python 3.12.x  
3. Install poetry & configure in-project virtualenvs  
4. Create project folder and initialise poetry  
5. Install core libraries (grouped by function)  
6. Test JupyterLab and VS Code  
7. Set up GitHub Copilot  
8. Initialise GitHub repo and push first commit  

---

## 🧠 AI Workflow
- **Copilot:** Inline coding assistance in VS Code  
- **ChatGPT ADA:** Data analysis, debugging, and planning in the Custom GPT  
- **Workflow:** Manual coding first → AI review & improvement → Publish results

---

## ✅ Phase 1 Deliverables
- Fully working Python data science environment on macOS  
- GitHub repo initialised with clean README.md  
- JupyterLab running with poetry kernel  
- GitHub Copilot enabled and tested  
- First AI-assisted analysis run in ChatGPT ADA

---

## 📅 Next Steps
- Start Phase 2: First project — Scraping → Cleaning → Visualization → Tableau Public dashboard
